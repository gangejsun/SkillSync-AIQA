# Sprint 2: AI Usage Dashboard - Tasks (TDD)

## ğŸ”´ RED â†’ ğŸŸ¢ GREEN â†’ ğŸ”µ REFACTOR

Every task follows TDD cycle:
1. Write failing test (RED)
2. Make test pass (GREEN)
3. Improve code (REFACTOR)
4. Commit

---

## Day 1: Backend Connect Endpoint â³ NOT STARTED

### Setup
- [ ] Create service directories if not exists
  ```bash
  cd services/ai-usage-service/src
  mkdir -p __tests__/{routes,controllers,services,utils}
  ```
  - Acceptance: Test directories exist

### Feature: Encryption Utilities (TDD)
- [ ] ğŸ”´ Write test: encrypt() encrypts text
  - File: `src/__tests__/utils/crypto.test.ts`
  - Test: input â†’ encrypted â†’ different from input
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement encrypt()
  - File: `src/utils/crypto.ts`
  - Use crypto.createCipheriv (AES-256-CBC)
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: decrypt() decrypts correctly
  - Test: encrypt(text) â†’ decrypt â†’ equals original text
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement decrypt()
  - Use crypto.createDecipheriv
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: decrypt() throws on invalid input
  - Test: decrypt('invalid') â†’ throws Error
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Add error handling to decrypt()
  - Try-catch with meaningful error
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”µ Refactor crypto.ts
  - Extract key generation
  - Add JSDoc comments
  - Run: `npm test` â†’ PASSES âœ“

### Feature: POST /api/ai-usage/connect (TDD)
- [ ] ğŸ”´ Write test: returns 401 if not authenticated
  - File: `src/__tests__/routes/usage.routes.test.ts`
  - Test: POST /api/ai-usage/connect without auth header â†’ 401
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Add auth middleware to route
  - File: `src/routes/usage.routes.ts`
  - Import and use auth middleware
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: returns 400 for invalid API key format
  - Test: POST with `api_key: "invalid"` â†’ 400
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement validation
  - File: `src/controllers/usage.controller.ts`
  - Validate API key format (regex)
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: stores encrypted API key in database
  - Test: POST with valid key â†’ database contains encrypted key
  - Mock Supabase
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement database storage
  - Call encrypt()
  - Insert into ai_tool_integrations table
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: returns integration_id on success
  - Test: POST â†’ response contains { success: true, integration_id: string }
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Return integration_id in response
  - Modify controller to return integration data
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: triggers initial sync (async)
  - Test: POST â†’ sync job queued
  - Mock sync service
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement async sync trigger
  - Fire-and-forget call to sync service
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”µ Refactor controller
  - Extract logic to service layer
  - Improve error messages
  - Run: `npm test` â†’ PASSES âœ“

### End of Day 1 Checklist
- [ ] All encryption tests pass
- [ ] All connect endpoint tests pass
- [ ] Code coverage â‰¥85%
- [ ] TypeScript compiles with no errors
- [ ] Commit: "feat(ai-usage): add connect endpoint with encryption (TDD)"

---

## Day 2: Mock Data + Dashboard Endpoint â³ NOT STARTED

### Feature: Mock Data Service (TDD)
- [ ] Create mock data file
  - File: `src/mock/ai_usage_data.json`
  - Content: Copy from PRD, ensure valid JSON
  - Acceptance: File exists, JSON valid

- [ ] ğŸ”´ Write test: loads mock data from file
  - File: `src/__tests__/services/mock-data.service.test.ts`
  - Test: MockDataService.getUserUsageData('mock-user-123') â†’ returns data
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement MockDataService.getUserUsageData()
  - File: `src/services/mock-data.service.ts`
  - Use fs.readFileSync + JSON.parse
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: returns null for non-existent user
  - Test: getUserUsageData('non-existent') â†’ null
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Add null check
  - Return null if user_id doesn't match
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”µ Refactor
  - Add caching (optional)
  - Add type definitions
  - Run: `npm test` â†’ PASSES âœ“

### Feature: Metrics Calculation (TDD)
- [ ] ğŸ”´ Write test: calculateTotalInteractions()
  - File: `src/__tests__/services/metrics.service.test.ts`
  - Input: array of metrics
  - Output: sum of request_count
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement calculateTotalInteractions()
  - File: `src/services/metrics.service.ts`
  - Use Array.reduce()
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: calculateActiveDays()
  - Input: metrics array
  - Output: count of unique dates with count > 0
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement calculateActiveDays()
  - Use Set to get unique dates
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: identifyTopTool()
  - Input: metrics array
  - Output: { name, requests } for tool with most requests
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement identifyTopTool()
  - Group by tool_name, sum requests
  - Return max
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: generateHeatmapData()
  - Input: metrics, days: 90
  - Output: array of 90 objects { date, count }
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement generateHeatmapData()
  - Fill missing dates with count: 0
  - Sort by date
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”µ Refactor metrics.service.ts
  - Optimize algorithms
  - Add JSDoc
  - Run: `npm test` â†’ PASSES âœ“

### Feature: GET /api/ai-usage/dashboard (TDD)
- [ ] ğŸ”´ Write test: returns 401 if not authenticated
  - File: `src/__tests__/routes/usage.routes.test.ts`
  - GET /api/ai-usage/dashboard without auth â†’ 401
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Add auth middleware
  - Add to route
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: returns aggregated data (mock mode)
  - Test: GET /dashboard?days=90 â†’ { total_interactions, active_days, top_tool, tools, heatmap_data }
  - Set USE_MOCK_DATA=true
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement getDashboard() controller
  - Load mock data
  - Call metrics service methods
  - Return aggregated data
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: heatmap_data has exactly 90 entries
  - Assert: response.body.heatmap_data.length === 90
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Ensure heatmap always returns 90 days
  - Modify generateHeatmapData()
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: respects days query parameter
  - GET /dashboard?days=30 â†’ 30 days of heatmap
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Add days parameter handling
  - Parse query param
  - Pass to generateHeatmapData()
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”µ Refactor controller
  - Extract business logic to service
  - Improve response structure
  - Run: `npm test` â†’ PASSES âœ“

### End of Day 2 Checklist
- [ ] Mock data service tests pass
- [ ] Metrics calculation tests pass
- [ ] Dashboard endpoint tests pass
- [ ] Code coverage â‰¥85%
- [ ] Commit: "feat(ai-usage): add dashboard endpoint with metrics (TDD)"

---

## Day 3: UI Components Part 1 â³ NOT STARTED

### Feature: UsageSummaryCard (TDD)
- [ ] ğŸ”´ Write test: renders title and value
  - File: `frontend/tests/components/cards/UsageSummaryCard.test.tsx`
  - Test: renders "Total Interactions" and "4,208"
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Create UsageSummaryCard component
  - File: `frontend/components/cards/UsageSummaryCard.tsx`
  - Accept props: title, value, subtitle
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: formats numbers with commas
  - Test: value 1234567 â†’ displays "1,234,567"
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Add number formatting
  - Use toLocaleString()
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: displays subtitle
  - Test: subtitle "Last 90 days" â†’ visible
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Add subtitle display
  - Render subtitle prop
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”µ Refactor
  - Add Tailwind classes from design system
  - Add icon support (optional)
  - Run: `npm test` â†’ PASSES âœ“

### Feature: UsageBarChart (TDD)
- [ ] ğŸ”´ Write test: renders tool names
  - File: `frontend/tests/components/charts/UsageBarChart.test.tsx`
  - Test: displays "Claude Code", "Cursor", "Copilot"
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Create UsageBarChart component
  - File: `frontend/components/charts/UsageBarChart.tsx`
  - Map over data and render tool names
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: displays request counts
  - Test: shows "1,842 requests"
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Add request count display
  - Format with toLocaleString()
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: calculates bar width as percentage
  - Test: Claude Code bar width = 43.78% (1842/4208 * 100)
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement percentage calculation
  - Calculate: (tool.requests / totalInteractions) * 100
  - Apply as inline style width
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: applies correct colors
  - Test: each tool has its designated color
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Add color support
  - Accept color prop or use default palette
  - Apply bg-color class
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”µ Refactor
  - Animate bar widths (optional)
  - Improve accessibility (aria-labels)
  - Run: `npm test` â†’ PASSES âœ“

### End of Day 3 Checklist
- [ ] UsageSummaryCard tests pass
- [ ] UsageBarChart tests pass
- [ ] Components render correctly
- [ ] Code coverage â‰¥75%
- [ ] Commit: "feat(ai-usage): add summary card and bar chart (TDD)"

---

## Day 4: UI Components Part 2 â³ NOT STARTED

### Feature: ActivityHeatmap (TDD)
- [ ] ğŸ”´ Write test: renders 90 day cells
  - File: `frontend/tests/components/charts/ActivityHeatmap.test.tsx`
  - Test: container has 90 cells
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Create ActivityHeatmap component
  - File: `frontend/components/charts/ActivityHeatmap.tsx`
  - Map over data (90 entries) and render cells
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: applies correct color intensity
  - Test: count 0 â†’ gray-100, count 5 â†’ primary-200, count 15 â†’ primary-600
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement color intensity logic
  - Function: getColorClass(count)
  - 0 â†’ gray, 1-5 â†’ light, 6-15 â†’ medium, 16+ â†’ dark
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: shows tooltip on hover
  - Test: hover cell â†’ tooltip shows "Nov 1: 25 requests"
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Add tooltip
  - Use Radix UI Tooltip or title attribute
  - Format: `${date}: ${count} requests`
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: displays legend
  - Test: "Less active" and "More active" labels visible
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Add legend
  - Render color scale legend
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”µ Refactor
  - Organize cells in grid (13 weeks Ã— 7 days)
  - Add smooth transitions
  - Run: `npm test` â†’ PASSES âœ“

### End of Day 4 Checklist
- [ ] ActivityHeatmap tests pass
- [ ] Heatmap displays correctly
- [ ] All UI component tests pass
- [ ] Commit: "feat(ai-usage): add activity heatmap (TDD)"

---

## Day 5: Pages Integration â³ NOT STARTED

### Feature: AIUsageConnectPage (TDD)
- [ ] ğŸ”´ Write test: renders connection form
  - File: `frontend/tests/app/(dashboard)/ai-usage/connect/page.test.tsx`
  - Test: form renders with API key input
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Create AIUsageConnectPage
  - File: `frontend/app/(dashboard)/ai-usage/connect/page.tsx`
  - Render form with input and submit button
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: validates API key format
  - Test: invalid key â†’ error message
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Add client-side validation
  - Regex: /^sk-ant-api\d+-[\w-]+$/
  - Show error message
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: calls API on submit
  - Test: valid key â†’ POST /api/ai-usage/connect
  - Mock API with MSW
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement form submission
  - Use fetch or axios
  - Handle response
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: shows success message
  - Test: API success â†’ "Connected successfully"
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Add success state
  - Show success message
  - Redirect to dashboard (optional)
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”µ Refactor
  - Use React Hook Form
  - Improve UX with loading state
  - Run: `npm test` â†’ PASSES âœ“

### Feature: AIUsagePage (Dashboard) (TDD)
- [ ] ğŸ”´ Write test: shows loading spinner
  - File: `frontend/tests/app/(dashboard)/ai-usage/page.test.tsx`
  - Test: loading state â†’ spinner visible
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Create AIUsagePage with loading state
  - File: `frontend/app/(dashboard)/ai-usage/page.tsx`
  - Use React Query or useState
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: fetches and displays data
  - Test: API returns data â†’ components render with data
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement data fetching
  - Call GET /api/ai-usage/dashboard
  - Pass data to components
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: shows error message on API failure
  - Test: API 500 â†’ error message + retry button
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Add error handling
  - Catch errors
  - Show error UI with retry
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”µ Refactor
  - Extract data fetching to custom hook
  - Add refresh button
  - Run: `npm test` â†’ PASSES âœ“

### End of Day 5 Checklist
- [ ] Connect page tests pass
- [ ] Dashboard page tests pass
- [ ] Integration works end-to-end
- [ ] Commit: "feat(ai-usage): add connect and dashboard pages (TDD)"

---

## Day 6: LinkedIn Share â³ NOT STARTED

### Feature: Share Image Generation (Backend TDD)
- [ ] ğŸ”´ Write test: generates image buffer
  - File: `services/badge-service/src/__tests__/services/share-image.service.test.ts`
  - Test: generateUsageImage(stats) â†’ returns Buffer
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement ShareImageService
  - File: `services/badge-service/src/services/share-image.service.ts`
  - Use canvas or sharp library
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: image contains stats
  - Test: image includes total_interactions text
  - (Manual verification or OCR)
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Draw text on canvas
  - Add usage stats to image
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”µ Refactor
  - Apply design system colors
  - Add SkillSync branding
  - Run: `npm test` â†’ PASSES âœ“

### Feature: LinkedIn Share Button (Frontend TDD)
- [ ] ğŸ”´ Write test: renders button
  - File: `frontend/tests/components/buttons/LinkedInShareButton.test.tsx`
  - Test: button renders
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Create LinkedInShareButton
  - File: `frontend/components/buttons/LinkedInShareButton.tsx`
  - Render button
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”´ Write test: opens LinkedIn share dialog
  - Test: click â†’ window.open with LinkedIn URL
  - Run: `npm test` â†’ FAILS âœ—

- [ ] ğŸŸ¢ Implement onClick handler
  - Generate LinkedIn share URL
  - Call window.open()
  - Run: `npm test` â†’ PASSES âœ“

- [ ] ğŸ”µ Refactor
  - Add loading state while generating image
  - Improve button styles
  - Run: `npm test` â†’ PASSES âœ“

### End of Day 6 Checklist
- [ ] Share image generation works
- [ ] LinkedIn share button works
- [ ] All tests pass
- [ ] Commit: "feat(ai-usage): add LinkedIn sharing (TDD)"

---

## Day 7: Polish & Bug Fixes â³ NOT STARTED

### Code Quality
- [ ] Run full test suite
  - Frontend: `cd frontend && npm test`
  - Backend: `cd services/ai-usage-service && npm test`
  - All pass âœ“

- [ ] Check code coverage
  - Frontend: â‰¥80%
  - Backend: â‰¥85%
  - If below, add more tests

- [ ] Run linter
  - `npm run lint` â†’ 0 errors

- [ ] TypeScript check
  - `npx tsc --noEmit` â†’ 0 errors

### Edge Cases & Error Handling
- [ ] Test: Dashboard with no data (empty state)
- [ ] Test: API timeout handling
- [ ] Test: Network offline scenario
- [ ] Test: Invalid API responses
- [ ] Test: Large numbers (millions)

### Refactoring
- [ ] Extract repeated code into utilities
- [ ] Improve component prop types
- [ ] Add JSDoc comments
- [ ] Optimize performance (memo, useMemo)

### Documentation
- [ ] Update TESTING_GUIDE.md with new examples
- [ ] Add inline code comments for complex logic
- [ ] Create CHANGELOG.md entry

### Final Commits
- [ ] Commit: "refactor(ai-usage): improve code quality"
- [ ] Commit: "docs(ai-usage): update documentation"
- [ ] Create PR for code review

---

## Sprint 2 Completion Checklist

### Functionality
- [ ] Users can connect AI tools via API key
- [ ] Dashboard displays usage statistics
- [ ] Bar chart shows tool breakdown
- [ ] Heatmap shows activity over 90 days
- [ ] Users can share on LinkedIn

### Tests
- [ ] All unit tests pass
- [ ] All integration tests pass
- [ ] Coverage â‰¥80% frontend, â‰¥85% backend
- [ ] No flaky tests

### Code Quality
- [ ] TypeScript: 0 errors
- [ ] ESLint: 0 warnings
- [ ] Formatted with Prettier
- [ ] No console.log or debugger

### Performance
- [ ] Dashboard loads in <1 second (mock data)
- [ ] Charts render smoothly
- [ ] No memory leaks

### Ready for Sprint 3
- [ ] Sprint 2 complete
- [ ] Code merged to main
- [ ] Documentation updated
- [ ] Team ready for Challenge System

---

## Quick Commands

```bash
# Run tests
cd frontend && npm test
cd services/ai-usage-service && npm test

# Watch mode
npm test -- --watch

# Coverage
npm test -- --coverage

# Single file
npm test UsageSummaryCard.test.tsx
```
